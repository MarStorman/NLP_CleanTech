{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "4e3323bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "abd1a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ ALL FILES\n",
    "\n",
    "# Read the JSON file\n",
    "results_json = pd.read_json(\"bq-results-20240124-055833-1706076079048.json\", lines=True)\n",
    "\n",
    "# Read the first CSV file\n",
    "ct_media = pd.read_csv(\"cleantech_media_dataset_v2_2024-02-23.csv\")\n",
    "\n",
    "# Read the second CSV file\n",
    "ct_evaluation = pd.read_csv(\"cleantech_rag_evaluation_data_2024-02-23.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "c11621d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows:\n",
      "  publication_number application_number country_code  \\\n",
      "0   US-2022239235-A1  US-202217717397-A           US   \n",
      "1   US-2022239251-A1  US-202217580956-A           US   \n",
      "2      EP-4033090-A1      EP-21152924-A           EP   \n",
      "3      EP-4033090-A1      EP-21152924-A           EP   \n",
      "4     US-11396827-B2  US-202117606042-A           US   \n",
      "\n",
      "                                     title_localized  \\\n",
      "0  [{'text': 'Adaptable DC-AC Inverter Drive Syst...   \n",
      "1  [{'text': 'System for providing the energy fro...   \n",
      "2  [{'text': 'Verfahren zum steuern einer windene...   \n",
      "3  [{'text': 'Verfahren zum steuern einer windene...   \n",
      "4  [{'text': 'Control method for optimizing solar...   \n",
      "\n",
      "                                  abstract_localized  publication_date  \\\n",
      "0  [{'text': 'Disclosed is an adaptable DC-AC inv...          20220728   \n",
      "1  [{'text': 'In accordance with an example embod...          20220728   \n",
      "2  [{'text': 'Verfahren zum Steuern einer Windene...          20220727   \n",
      "3  [{'text': 'Verfahren zum Steuern einer Windene...          20220727   \n",
      "4  [{'text': 'A control method for optimizing a s...          20220726   \n",
      "\n",
      "                                            inventor  \\\n",
      "0                                                 []   \n",
      "1                                                 []   \n",
      "2  [Schaper, Ulf, von Aswege, Enno, Gerke Funcke,...   \n",
      "3  [Schaper, Ulf, von Aswege, Enno, Gerke Funcke,...   \n",
      "4                                                 []   \n",
      "\n",
      "                                                 cpc  \n",
      "0  [{'code': 'H02M7/5395', 'inventive': True, 'fi...  \n",
      "1  [{'code': 'H02S40/38', 'inventive': True, 'fir...  \n",
      "2  [{'code': 'F03D7/0276', 'inventive': True, 'fi...  \n",
      "3  [{'code': 'F03D7/0276', 'inventive': True, 'fi...  \n",
      "4  [{'code': 'F24S50/00', 'inventive': True, 'fir...  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the DataFrame\n",
    "print(\"First few rows:\")\n",
    "print(results_json.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "16542bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   publication_number  30000 non-null  object\n",
      " 1   application_number  30000 non-null  object\n",
      " 2   country_code        30000 non-null  object\n",
      " 3   title_localized     30000 non-null  object\n",
      " 4   abstract_localized  30000 non-null  object\n",
      " 5   publication_date    30000 non-null  int64 \n",
      " 6   inventor            30000 non-null  object\n",
      " 7   cpc                 30000 non-null  object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 1.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display basic information about the DataFrame\n",
    "print(\"\\nData information:\")\n",
    "print(results_json.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8bf2de1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics:\n",
      "       publication_date\n",
      "count      3.000000e+04\n",
      "mean       2.021843e+07\n",
      "std        3.783564e+03\n",
      "min        2.021112e+07\n",
      "25%        2.022011e+07\n",
      "50%        2.022032e+07\n",
      "75%        2.022052e+07\n",
      "max        2.022073e+07\n"
     ]
    }
   ],
   "source": [
    "# Display summary statistics for numerical columns\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(results_json.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "3b8998be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows:\n",
      "   Unnamed: 0                                              title        date  \\\n",
      "0        1280  Qatar to Slash Emissions as LNG Expansion Adva...  2021-01-13   \n",
      "1        1281               India Launches Its First 700 MW PHWR  2021-01-15   \n",
      "2        1283              New Chapter for US-China Energy Trade  2021-01-20   \n",
      "3        1284  Japan: Slow Restarts Cast Doubt on 2030 Energy...  2021-01-22   \n",
      "4        1285     NYC Pension Funds to Divest Fossil Fuel Shares  2021-01-25   \n",
      "\n",
      "  author                                            content       domain  \\\n",
      "0    NaN  [\"Qatar Petroleum ( QP) is targeting aggressiv...  energyintel   \n",
      "1    NaN  [\"• Nuclear Power Corp. of India Ltd. ( NPCIL)...  energyintel   \n",
      "2    NaN  [\"New US President Joe Biden took office this ...  energyintel   \n",
      "3    NaN  [\"The slow pace of Japanese reactor restarts c...  energyintel   \n",
      "4    NaN  [\"Two of New York City's largest pension funds...  energyintel   \n",
      "\n",
      "                                                 url  \n",
      "0  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
      "1  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
      "2  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
      "3  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
      "4  https://www.energyintel.com/0000017b-a7dc-de4c...  \n"
     ]
    }
   ],
   "source": [
    "print(\"First few rows:\")\n",
    "print(ct_media.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "4c98ab10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows:\n",
      "   example_id  question_id                                           question  \\\n",
      "0           1            1  What is the innovation behind Leclanché's new ...   \n",
      "1           2            2       What is the EU’s Green Deal Industrial Plan?   \n",
      "2           3            2       What is the EU’s Green Deal Industrial Plan?   \n",
      "3           4            3  What are the four focus areas of the EU's Gree...   \n",
      "4           5            4  When did the cooperation between GM and Honda ...   \n",
      "\n",
      "                                      relevant_chunk  \\\n",
      "0  Leclanché said it has developed an environment...   \n",
      "1  The Green Deal Industrial Plan is a bid by the...   \n",
      "2  The European counterpart to the US Inflation R...   \n",
      "3  The new plan is fundamentally focused on four ...   \n",
      "4  What caught our eye was a new hookup between G...   \n",
      "\n",
      "                                         article_url  \n",
      "0  https://www.sgvoice.net/strategy/technology/23...  \n",
      "1  https://www.sgvoice.net/policy/25396/eu-seeks-...  \n",
      "2  https://www.pv-magazine.com/2023/02/02/europea...  \n",
      "3  https://www.sgvoice.net/policy/25396/eu-seeks-...  \n",
      "4  https://cleantechnica.com/2023/05/08/general-m...  \n"
     ]
    }
   ],
   "source": [
    "print(\"First few rows:\")\n",
    "print(ct_evaluation.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b1c6cd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop duplicates CSV\n",
    "#ct_media.drop_duplicates(inplace=True)\n",
    "#ct_evaluation.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6251209",
   "metadata": {},
   "source": [
    "### JSON text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "59b10162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  publication_number application_number country_code  \\\n",
      "0   US-2022239235-A1  US-202217717397-A           US   \n",
      "1   US-2022239251-A1  US-202217580956-A           US   \n",
      "2      EP-4033090-A1      EP-21152924-A           EP   \n",
      "3      EP-4033090-A1      EP-21152924-A           EP   \n",
      "4     US-11396827-B2  US-202117606042-A           US   \n",
      "\n",
      "                                     title_localized  \\\n",
      "0  [{'text': 'Adaptable DC-AC Inverter Drive Syst...   \n",
      "1  [{'text': 'System for providing the energy fro...   \n",
      "2  [{'text': 'Verfahren zum steuern einer windene...   \n",
      "3  [{'text': 'Verfahren zum steuern einer windene...   \n",
      "4  [{'text': 'Control method for optimizing solar...   \n",
      "\n",
      "                                  abstract_localized  publication_date  \\\n",
      "0  [{'text': 'Disclosed is an adaptable DC-AC inv...          20220728   \n",
      "1  [{'text': 'In accordance with an example embod...          20220728   \n",
      "2  [{'text': 'Verfahren zum Steuern einer Windene...          20220727   \n",
      "3  [{'text': 'Verfahren zum Steuern einer Windene...          20220727   \n",
      "4  [{'text': 'A control method for optimizing a s...          20220726   \n",
      "\n",
      "                                            inventor  \\\n",
      "0                                                 []   \n",
      "1                                                 []   \n",
      "2  [Schaper, Ulf, von Aswege, Enno, Gerke Funcke,...   \n",
      "3  [Schaper, Ulf, von Aswege, Enno, Gerke Funcke,...   \n",
      "4                                                 []   \n",
      "\n",
      "                                                 cpc  \n",
      "0  [{'code': 'H02M7/5395', 'inventive': True, 'fi...  \n",
      "1  [{'code': 'H02S40/38', 'inventive': True, 'fir...  \n",
      "2  [{'code': 'F03D7/0276', 'inventive': True, 'fi...  \n",
      "3  [{'code': 'F03D7/0276', 'inventive': True, 'fi...  \n",
      "4  [{'code': 'F24S50/00', 'inventive': True, 'fir...  \n"
     ]
    }
   ],
   "source": [
    "print(results_json.head())\n",
    "# Based on the output, we have to change the date into readable form, preprocess publication and application number, clean title and abstract, address the missing in inventor and separate the cpc column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d551f4a3",
   "metadata": {},
   "source": [
    "#### Change date format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a39cf1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change JSON date format\n",
    "results_json['publication_date'] = pd.to_datetime(results_json['publication_date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036cd755",
   "metadata": {},
   "source": [
    "#### Convert \"cpc\" column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e893eaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 'cpc' column:\n",
      "0    [{'code': 'H02M7/5395', 'inventive': True, 'fi...\n",
      "1    [{'code': 'H02S40/38', 'inventive': True, 'fir...\n",
      "2    [{'code': 'F03D7/0276', 'inventive': True, 'fi...\n",
      "3    [{'code': 'F03D7/0276', 'inventive': True, 'fi...\n",
      "4    [{'code': 'F24S50/00', 'inventive': True, 'fir...\n",
      "Name: cpc, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Inspect cpc column and handle it, second try #first time it worked and then it did not, so I might have a code that overwrite the column\n",
    "print(\"Checking 'cpc' column:\")\n",
    "print(results_json['cpc'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "5bbc42d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying 'cpc' after applying extract_first_cpc function:\n",
      "0    {'code': 'H02M7/5395', 'inventive': True, 'fir...\n",
      "1    {'code': 'H02S40/38', 'inventive': True, 'firs...\n",
      "2    {'code': 'F03D7/0276', 'inventive': True, 'fir...\n",
      "3    {'code': 'F03D7/0276', 'inventive': True, 'fir...\n",
      "4    {'code': 'F24S50/00', 'inventive': True, 'firs...\n",
      "Name: cpc, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Redefine the function for extracting the first CPC entry\n",
    "def extract_first_cpc(cpc_entry):\n",
    "    if cpc_entry and isinstance(cpc_entry, list) and len(cpc_entry) > 0:\n",
    "        return cpc_entry[0]\n",
    "    return None\n",
    "\n",
    "# Apply the function to the 'cpc' column\n",
    "results_json['cpc'] = results_json['cpc'].apply(extract_first_cpc)\n",
    "\n",
    "# Verify that the function worked as expected\n",
    "print(\"\\nVerifying 'cpc' after applying extract_first_cpc function:\")\n",
    "print(results_json['cpc'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "49afc1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final 'cpc' related columns:\n",
      "     cpc_code cpc_inventive cpc_first cpc_tree\n",
      "0  H02M7/5395          True     False       []\n",
      "1   H02S40/38          True     False       []\n",
      "2  F03D7/0276          True      True       []\n",
      "3  F03D7/0276          True      True       []\n",
      "4   F24S50/00          True     False       []\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'cpc' is now properly formatted, apply lambda functions to create new columns\n",
    "results_json['cpc_code'] = results_json['cpc'].apply(lambda x: x.get('code') if isinstance(x, dict) and 'code' in x else None)\n",
    "results_json['cpc_inventive'] = results_json['cpc'].apply(lambda x: x.get('inventive') if isinstance(x, dict) and 'inventive' in x else None)\n",
    "results_json['cpc_first'] = results_json['cpc'].apply(lambda x: x.get('first') if isinstance(x, dict) and 'first' in x else None)\n",
    "results_json['cpc_tree'] = results_json['cpc'].apply(lambda x: x.get('tree') if isinstance(x, dict) and 'tree' in x else None)\n",
    "\n",
    "# Now, let's check the new columns to ensure they contain the expected data\n",
    "print(\"\\nFinal 'cpc' related columns:\")\n",
    "print(results_json[['cpc_code', 'cpc_inventive', 'cpc_first', 'cpc_tree']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "7f7dfb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  publication_number application_number country_code  \\\n",
      "0         2022239235       202217717397           US   \n",
      "1         2022239251       202217580956           US   \n",
      "2            4033090           21152924           EP   \n",
      "3            4033090           21152924           EP   \n",
      "4           11396827       202117606042           US   \n",
      "\n",
      "                                     title_localized  \\\n",
      "0  [{'text': 'Adaptable DC-AC Inverter Drive Syst...   \n",
      "1  [{'text': 'System for providing the energy fro...   \n",
      "2  [{'text': 'Verfahren zum steuern einer windene...   \n",
      "3  [{'text': 'Verfahren zum steuern einer windene...   \n",
      "4  [{'text': 'Control method for optimizing solar...   \n",
      "\n",
      "                                  abstract_localized publication_date  \\\n",
      "0  [{'text': 'Disclosed is an adaptable DC-AC inv...       2022-07-28   \n",
      "1  [{'text': 'In accordance with an example embod...       2022-07-28   \n",
      "2  [{'text': 'Verfahren zum Steuern einer Windene...       2022-07-27   \n",
      "3  [{'text': 'Verfahren zum Steuern einer Windene...       2022-07-27   \n",
      "4  [{'text': 'A control method for optimizing a s...       2022-07-26   \n",
      "\n",
      "                                            inventor    cpc_code  \\\n",
      "0                                               None  H02M7/5395   \n",
      "1                                               None   H02S40/38   \n",
      "2  [Schaper, Ulf, Von Aswege, Enno, Gerke Funcke,...  F03D7/0276   \n",
      "3  [Schaper, Ulf, Von Aswege, Enno, Gerke Funcke,...  F03D7/0276   \n",
      "4                                               None   F24S50/00   \n",
      "\n",
      "  cpc_inventive cpc_first  num_inventors  multiple_inventors  \n",
      "0          True     False              0                   0  \n",
      "1          True     False              0                   0  \n",
      "2          True      True              3                   1  \n",
      "3          True      True              3                   1  \n",
      "4          True     False              0                   0  \n"
     ]
    }
   ],
   "source": [
    "# Verify the columns have been dropped by printing the DataFrame's head\n",
    "print(results_json.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29564289",
   "metadata": {},
   "source": [
    "#### Handle Missing in \"inventor\" and \"cpc_tree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "932e982f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All entries in 'cpc_tree' are empty lists or None: True\n"
     ]
    }
   ],
   "source": [
    "# Check if all entries in 'cpc_tree' are empty lists or None\n",
    "all_empty_trees = all(x == [] or x is None for x in results_json['cpc_tree'])\n",
    "print(\"All entries in 'cpc_tree' are empty lists or None:\", all_empty_trees)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "de1f35a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'cpc_tree' column\n",
    "results_json.drop(['cpc_tree'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b11fcfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'cpc' column\n",
    "results_json.drop(['cpc'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "1c32173f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of non-empty 'inventor' entries: 63.64666666666666%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of non-empty entries in 'inventor'\n",
    "non_empty_inventors = results_json['inventor'].apply(bool).mean() * 100\n",
    "print(f\"Percentage of non-empty 'inventor' entries: {non_empty_inventors}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "a5b7c951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            inventor  num_inventors  \\\n",
      "0                                               None              0   \n",
      "1                                               None              0   \n",
      "2  [Schaper, Ulf, Von Aswege, Enno, Gerke Funcke,...              3   \n",
      "3  [Schaper, Ulf, Von Aswege, Enno, Gerke Funcke,...              3   \n",
      "4                                               None              0   \n",
      "\n",
      "   multiple_inventors  \n",
      "0                   0  \n",
      "1                   0  \n",
      "2                   1  \n",
      "3                   1  \n",
      "4                   0  \n",
      "Distribution of number of inventors:\n",
      "0     10906\n",
      "1      6771\n",
      "2      2636\n",
      "3      2551\n",
      "4      1741\n",
      "5      1595\n",
      "6      1155\n",
      "7       799\n",
      "8       543\n",
      "9       328\n",
      "10      287\n",
      "11      157\n",
      "12      134\n",
      "13       92\n",
      "15       86\n",
      "14       70\n",
      "16       31\n",
      "18       27\n",
      "17       24\n",
      "20       22\n",
      "21       18\n",
      "19       14\n",
      "25        4\n",
      "22        3\n",
      "24        2\n",
      "38        2\n",
      "29        2\n",
      "Name: num_inventors, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Standardize the names in the 'inventor' column and handle missing data\n",
    "results_json['inventor'] = results_json['inventor'].apply(lambda x: [name.strip().title() for name in x] if x else None)\n",
    "\n",
    "# Create a new column for the count of inventors\n",
    "results_json['num_inventors'] = results_json['inventor'].apply(lambda x: len(x) if x else 0)\n",
    "\n",
    "# Create a binary indicator for multiple inventors\n",
    "results_json['multiple_inventors'] = results_json['num_inventors'].apply(lambda x: 1 if x > 1 else 0)\n",
    "\n",
    "# Check the results\n",
    "print(results_json[['inventor', 'num_inventors', 'multiple_inventors']].head())\n",
    "\n",
    "# Analyze the distribution of the number of inventors\n",
    "print(\"Distribution of number of inventors:\")\n",
    "print(results_json['num_inventors'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1b1ba1",
   "metadata": {},
   "source": [
    "#### Process publication and application number columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "65aa55d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null entries in 'country_code': 0\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in 'country_code', to see if I can safely remove codes integrated in publication adn application column\n",
    "null_country_codes = results_json['country_code'].isnull().sum()\n",
    "print(f\"Number of null entries in 'country_code': {null_country_codes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "2c7a95a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  publication_number application_number\n",
      "0         2022239235       202217717397\n",
      "1         2022239251       202217580956\n",
      "2            4033090           21152924\n",
      "3            4033090           21152924\n",
      "4           11396827       202117606042\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define a function to remove the prefix and suffix\n",
    "def remove_prefix_suffix(text):\n",
    "    # Remove the country code prefix\n",
    "    text = re.sub(r'^[A-Za-z]+-', '', text)\n",
    "    # Remove any suffix that starts with a dash after the numeric sequence\n",
    "    text = re.sub(r'-.+$', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply the function to the publication and application number columns\n",
    "results_json['publication_number'] = results_json['publication_number'].apply(remove_prefix_suffix)\n",
    "results_json['application_number'] = results_json['application_number'].apply(remove_prefix_suffix)\n",
    "\n",
    "# Display the DataFrame to confirm the changes\n",
    "print(results_json[['publication_number', 'application_number']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64d0bc0",
   "metadata": {},
   "source": [
    "### Text cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "b6aa2bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Check for null values in specific columns (adjust column names as per your DataFrame)\n",
    "print(results_json['abstract_localized'].isnull().sum())\n",
    "print(results_json['title_localized'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "6907ba36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       abstract_text  \\\n",
      "0  Disclosed is an adaptable DC-AC inverter syste...   \n",
      "1  In accordance with an example embodiment, a so...   \n",
      "2  Verfahren zum Steuern einer Windenergieanlage ...   \n",
      "3  Verfahren zum Steuern einer Windenergieanlage ...   \n",
      "4  A control method for optimizing a solar-to-pow...   \n",
      "\n",
      "                                          title_text  \n",
      "0  Adaptable DC-AC Inverter Drive System and Oper...  \n",
      "1  System for providing the energy from a single ...  \n",
      "2      Verfahren zum steuern einer windenergieanlage  \n",
      "3      Verfahren zum steuern einer windenergieanlage  \n",
      "4  Control method for optimizing solar-to-power e...  \n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_json(row):\n",
    "    if row and isinstance(row, list):\n",
    "        try:\n",
    "            # Extract the 'text' part from the first dictionary in the list\n",
    "            return row[0]['text']\n",
    "        except (IndexError, KeyError):\n",
    "            # Return None or some default value if there's an error in parsing\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# Applying the updated function to 'abstract_localized' and 'title_localized' to extract the 'text' part\n",
    "results_json['abstract_text'] = results_json['abstract_localized'].apply(extract_text_from_json)\n",
    "results_json['title_text'] = results_json['title_localized'].apply(extract_text_from_json)\n",
    "\n",
    "# Drop the original columns if they are no longer needed\n",
    "results_json.drop(columns=['abstract_localized', 'title_localized'], inplace=True)\n",
    "\n",
    "# Inspect the cleaned columns\n",
    "print(results_json[['abstract_text', 'title_text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "4c50dfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of effectively empty abstracts: 0\n",
      "Number of effectively empty titles: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for empty or whitespace-only strings\n",
    "empty_abstracts_count = results_json[results_json['abstract_text'].apply(lambda x: x.strip() == '')].shape[0]\n",
    "empty_titles_count = results_json[results_json['title_text'].apply(lambda x: x.strip() == '')].shape[0]\n",
    "\n",
    "print(f\"Number of effectively empty abstracts: {empty_abstracts_count}\")\n",
    "print(f\"Number of effectively empty titles: {empty_titles_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "c52161cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample entries from abstract_text:\n",
      "Series([], Name: abstract_text, dtype: object)\n",
      "Sample entries from title_text:\n",
      "Series([], Name: title_text, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "# Display some samples of entries that might be causing zero tokens\n",
    "print(\"Sample entries from abstract_text:\")\n",
    "print(results_json[results_json['abstract_text'].apply(lambda x: x.strip() == '')]['abstract_text'].head())\n",
    "\n",
    "print(\"Sample entries from title_text:\")\n",
    "print(results_json[results_json['title_text'].apply(lambda x: x.strip() == '')]['title_text'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "32bbd79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       abstract_text  \\\n",
      "0  disclosed is an adaptable dc ac inverter syste...   \n",
      "1  in accordance with an example embodiment a sol...   \n",
      "2  verfahren zum steuern einer windenergieanlage ...   \n",
      "3  verfahren zum steuern einer windenergieanlage ...   \n",
      "4  a control method for optimizing a solar to pow...   \n",
      "\n",
      "                                          title_text  \n",
      "0  adaptable dc ac inverter drive system and oper...  \n",
      "1  system for providing the energy from a single ...  \n",
      "2      verfahren zum steuern einer windenergieanlage  \n",
      "3      verfahren zum steuern einer windenergieanlage  \n",
      "4  control method for optimizing solar to power e...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    # Convert to lower case\n",
    "    text = text.lower()\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    # Remove unwanted characters, but preserve hyphens within words\n",
    "    text = re.sub(r'[^a-z\\s-]', '', text)\n",
    "    # Clean up any stray hyphens that do not form part of a hyphenated word\n",
    "    text = re.sub(r'\\b-\\b', ' ', text)\n",
    "    # Remove multiple spaces and trim\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Apply cleaning function to both columns\n",
    "results_json['abstract_text'] = results_json['abstract_text'].apply(clean_text)\n",
    "results_json['title_text'] = results_json['title_text'].apply(clean_text)\n",
    "\n",
    "# Print cleaned text for inspection\n",
    "print(results_json[['abstract_text', 'title_text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "6938ff90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   publication_number application_number country_code publication_date  \\\n",
      "0          2022239235       202217717397           US       2022-07-28   \n",
      "1          2022239251       202217580956           US       2022-07-28   \n",
      "2             4033090           21152924           EP       2022-07-27   \n",
      "3             4033090           21152924           EP       2022-07-27   \n",
      "4            11396827       202117606042           US       2022-07-26   \n",
      "5           114772674       202210500131           CN       2022-07-22   \n",
      "6           217026795       202220668705           CN       2022-07-22   \n",
      "7           114777546       202210702520           CN       2022-07-22   \n",
      "8           217027597       202220203603           CN       2022-07-22   \n",
      "9           217035692       202220372280           CN       2022-07-22   \n",
      "10          114785259       202210734862           CN       2022-07-22   \n",
      "11          217037096       202122316324           CN       2022-07-22   \n",
      "12          114771214       202210621034           CN       2022-07-22   \n",
      "13          114784439       202210348107           CN       2022-07-22   \n",
      "14          217013015       202123377139           CN       2022-07-22   \n",
      "15          114777032       202210409397           CN       2022-07-22   \n",
      "16          114776524       202210405869           CN       2022-07-22   \n",
      "17          114776525       202210474145           CN       2022-07-22   \n",
      "18          114769098       202210540479           CN       2022-07-22   \n",
      "19          114784880       202210475974           CN       2022-07-22   \n",
      "\n",
      "                                             inventor    cpc_code  \\\n",
      "0                                                None  H02M7/5395   \n",
      "1                                                None   H02S40/38   \n",
      "2   [Schaper, Ulf, Von Aswege, Enno, Gerke Funcke,...  F03D7/0276   \n",
      "3   [Schaper, Ulf, Von Aswege, Enno, Gerke Funcke,...  F03D7/0276   \n",
      "4                                                None   F24S50/00   \n",
      "5                                                None        None   \n",
      "6                                                None        None   \n",
      "7                                                None        None   \n",
      "8                                                None        None   \n",
      "9                                                None        None   \n",
      "10                                               None        None   \n",
      "11                                               None        None   \n",
      "12                                               None        None   \n",
      "13                                               None        None   \n",
      "14                                               None        None   \n",
      "15                                               None        None   \n",
      "16                                               None        None   \n",
      "17                                               None        None   \n",
      "18                                               None        None   \n",
      "19                                               None        None   \n",
      "\n",
      "   cpc_inventive cpc_first  num_inventors  multiple_inventors  \\\n",
      "0           True     False              0                   0   \n",
      "1           True     False              0                   0   \n",
      "2           True      True              3                   1   \n",
      "3           True      True              3                   1   \n",
      "4           True     False              0                   0   \n",
      "5           None      None              0                   0   \n",
      "6           None      None              0                   0   \n",
      "7           None      None              0                   0   \n",
      "8           None      None              0                   0   \n",
      "9           None      None              0                   0   \n",
      "10          None      None              0                   0   \n",
      "11          None      None              0                   0   \n",
      "12          None      None              0                   0   \n",
      "13          None      None              0                   0   \n",
      "14          None      None              0                   0   \n",
      "15          None      None              0                   0   \n",
      "16          None      None              0                   0   \n",
      "17          None      None              0                   0   \n",
      "18          None      None              0                   0   \n",
      "19          None      None              0                   0   \n",
      "\n",
      "                                        abstract_text  \\\n",
      "0   disclosed is an adaptable dc ac inverter syste...   \n",
      "1   in accordance with an example embodiment a sol...   \n",
      "2   verfahren zum steuern einer windenergieanlage ...   \n",
      "3   verfahren zum steuern einer windenergieanlage ...   \n",
      "4   a control method for optimizing a solar to pow...   \n",
      "5                                                       \n",
      "6                                              ledled   \n",
      "7   the invention relates to the technical field o...   \n",
      "8                        lowelowegigsgigsgigsgigslowe   \n",
      "9                                                       \n",
      "10                                                 ll   \n",
      "11                                                  u   \n",
      "12  the invention discloses a hydrogen energy auto...   \n",
      "13  the invention discloses a solar energy storage...   \n",
      "14                                                      \n",
      "15                                                      \n",
      "16                                fsrulngfsrufsrufsru   \n",
      "17  the invention discloses a wind power generatio...   \n",
      "18  the application discloses a solar energy absor...   \n",
      "19                                                      \n",
      "\n",
      "                                           title_text  \\\n",
      "0   adaptable dc ac inverter drive system and oper...   \n",
      "1   system for providing the energy from a single ...   \n",
      "2       verfahren zum steuern einer windenergieanlage   \n",
      "3       verfahren zum steuern einer windenergieanlage   \n",
      "4   control method for optimizing solar to power e...   \n",
      "5   low carbon running saline wastewater treatment...   \n",
      "6   water ecological remediation device convenient...   \n",
      "7   cold and hot medium energy storage hot water a...   \n",
      "8   solar energy respiratory wall based on princip...   \n",
      "9                                                       \n",
      "10                                                      \n",
      "11  solar photovoltaic aluminum frame protection s...   \n",
      "12                                                      \n",
      "13                                                      \n",
      "14                umbrella with illumination function   \n",
      "15  water conservancy water and electricity detect...   \n",
      "16  shipborne cold energy and wind energy hybrid p...   \n",
      "17               wind power generation driving device   \n",
      "18        solar energy absorption coating steel plate   \n",
      "19  water and electricity control method device eq...   \n",
      "\n",
      "                                      abstract_tokens  \\\n",
      "0   [disclosed, is, an, adaptable, dc, ac, inverte...   \n",
      "1   [in, accordance, with, an, example, embodiment...   \n",
      "2   [verfahren, zum, steuern, einer, windenergiean...   \n",
      "3   [verfahren, zum, steuern, einer, windenergiean...   \n",
      "4   [a, control, method, for, optimizing, a, solar...   \n",
      "5                                                  []   \n",
      "6                                            [ledled]   \n",
      "7   [the, invention, relates, to, the, technical, ...   \n",
      "8                      [lowelowegigsgigsgigsgigslowe]   \n",
      "9                                                  []   \n",
      "10                                               [ll]   \n",
      "11                                                [u]   \n",
      "12  [the, invention, discloses, a, hydrogen, energ...   \n",
      "13  [the, invention, discloses, a, solar, energy, ...   \n",
      "14                                                 []   \n",
      "15                                                 []   \n",
      "16                              [fsrulngfsrufsrufsru]   \n",
      "17  [the, invention, discloses, a, wind, power, ge...   \n",
      "18  [the, application, discloses, a, solar, energy...   \n",
      "19                                                 []   \n",
      "\n",
      "                                         title_tokens  abstract_token_count  \\\n",
      "0   [adaptable, dc, ac, inverter, drive, system, a...                    67   \n",
      "1   [system, for, providing, the, energy, from, a,...                    92   \n",
      "2   [verfahren, zum, steuern, einer, windenergiean...                   208   \n",
      "3   [verfahren, zum, steuern, einer, windenergiean...                   208   \n",
      "4   [control, method, for, optimizing, solar, to, ...                   166   \n",
      "5   [low, carbon, running, saline, wastewater, tre...                     0   \n",
      "6   [water, ecological, remediation, device, conve...                     1   \n",
      "7   [cold, and, hot, medium, energy, storage, hot,...                    72   \n",
      "8   [solar, energy, respiratory, wall, based, on, ...                     1   \n",
      "9                                                  []                     0   \n",
      "10                                                 []                     1   \n",
      "11  [solar, photovoltaic, aluminum, frame, protect...                     1   \n",
      "12                                                 []                   210   \n",
      "13                                                 []                   163   \n",
      "14           [umbrella, with, illumination, function]                     0   \n",
      "15  [water, conservancy, water, and, electricity, ...                     0   \n",
      "16  [shipborne, cold, energy, and, wind, energy, h...                     1   \n",
      "17         [wind, power, generation, driving, device]                   227   \n",
      "18  [solar, energy, absorption, coating, steel, pl...                   126   \n",
      "19  [water, and, electricity, control, method, dev...                     0   \n",
      "\n",
      "    title_token_count abstract_language title_language  \n",
      "0                   8                en             en  \n",
      "1                  18                en             en  \n",
      "2                   5                de             de  \n",
      "3                   5                de             de  \n",
      "4                  20                en             en  \n",
      "5                  16             error             en  \n",
      "6                   8                da             en  \n",
      "7                  17                en             en  \n",
      "8                  10                af             en  \n",
      "9                   0             error          error  \n",
      "10                  0                ca          error  \n",
      "11                  6                fr             ro  \n",
      "12                  0                en          error  \n",
      "13                  0                en          error  \n",
      "14                  4             error             en  \n",
      "15                  9             error             en  \n",
      "16                 13                de             en  \n",
      "17                  5                en             en  \n",
      "18                  6                en             en  \n",
      "19                 10             error             en  \n"
     ]
    }
   ],
   "source": [
    "#\n",
    "print(results_json.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "5bca4e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for null values again\n",
    "print(results_json['abstract_text'].isnull().sum())\n",
    "print(results_json['title_text'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "e7d4a10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\maaru\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token counts in abstracts and titles:\n",
      "                                       abstract_text  abstract_token_count  \\\n",
      "0  disclosed is an adaptable dc ac inverter syste...                    67   \n",
      "1  in accordance with an example embodiment a sol...                    92   \n",
      "2  verfahren zum steuern einer windenergieanlage ...                   208   \n",
      "3  verfahren zum steuern einer windenergieanlage ...                   208   \n",
      "4  a control method for optimizing a solar to pow...                   166   \n",
      "\n",
      "                                          title_text  title_token_count  \n",
      "0  adaptable dc ac inverter drive system and oper...                  8  \n",
      "1  system for providing the energy from a single ...                 18  \n",
      "2      verfahren zum steuern einer windenergieanlage                  5  \n",
      "3      verfahren zum steuern einer windenergieanlage                  5  \n",
      "4  control method for optimizing solar to power e...                 20  \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# You might need to ensure NLTK's resources are available\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Tokenizing text\n",
    "results_json['abstract_tokens'] = results_json['abstract_text'].apply(word_tokenize)\n",
    "results_json['title_tokens'] = results_json['title_text'].apply(word_tokenize)\n",
    "\n",
    "# Counting tokens\n",
    "results_json['abstract_token_count'] = results_json['abstract_tokens'].apply(len)\n",
    "results_json['title_token_count'] = results_json['title_tokens'].apply(len)\n",
    "\n",
    "# Print to verify\n",
    "print(\"Token counts in abstracts and titles:\")\n",
    "print(results_json[['abstract_text', 'abstract_token_count', 'title_text', 'title_token_count']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c698c1",
   "metadata": {},
   "source": [
    "### Detect languages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "11352915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ---- --------------------------------- 112.6/981.5 kB 3.3 MB/s eta 0:00:01\n",
      "     ----------- -------------------------- 286.7/981.5 kB 3.0 MB/s eta 0:00:01\n",
      "     ----------------------- -------------- 604.2/981.5 kB 4.2 MB/s eta 0:00:01\n",
      "     -------------------------------------  972.8/981.5 kB 5.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 981.5/981.5 kB 5.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six in c:\\users\\maaru\\anaconda3\\lib\\site-packages (from langdetect) (1.16.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993253 sha256=b2cd51aab8d21c7b3580f512863f80f9cc702c9af941e201ae80dbcd84fe7089\n",
      "  Stored in directory: c:\\users\\maaru\\appdata\\local\\pip\\cache\\wheels\\0a\\f2\\b2\\e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "4f9b6bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       abstract_text abstract_language  \\\n",
      "0  disclosed is an adaptable dc ac inverter syste...                en   \n",
      "1  in accordance with an example embodiment a sol...                en   \n",
      "2  verfahren zum steuern einer windenergieanlage ...                de   \n",
      "3  verfahren zum steuern einer windenergieanlage ...                de   \n",
      "4  a control method for optimizing a solar to pow...                en   \n",
      "\n",
      "                                          title_text title_language  \n",
      "0  adaptable dc ac inverter drive system and oper...             en  \n",
      "1  system for providing the energy from a single ...             en  \n",
      "2      verfahren zum steuern einer windenergieanlage             de  \n",
      "3      verfahren zum steuern einer windenergieanlage             de  \n",
      "4  control method for optimizing solar to power e...             en  \n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "# Function to detect language\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return \"error\"  # Returns \"error\" if the language detection fails\n",
    "\n",
    "# Apply language detection to abstracts and titles\n",
    "results_json['abstract_language'] = results_json['abstract_text'].apply(detect_language)\n",
    "results_json['title_language'] = results_json['title_text'].apply(detect_language)\n",
    "\n",
    "# Print to verify\n",
    "print(results_json[['abstract_text', 'abstract_language', 'title_text', 'title_language']].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "72d6064f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        abstract_text abstract_language  \\\n",
      "0   disclosed is an adaptable dc ac inverter syste...                en   \n",
      "1   in accordance with an example embodiment a sol...                en   \n",
      "2   verfahren zum steuern einer windenergieanlage ...                de   \n",
      "3   verfahren zum steuern einer windenergieanlage ...                de   \n",
      "4   a control method for optimizing a solar to pow...                en   \n",
      "5                                                                 error   \n",
      "6                                              ledled                da   \n",
      "7   the invention relates to the technical field o...                en   \n",
      "8                        lowelowegigsgigsgigsgigslowe                af   \n",
      "9                                                                 error   \n",
      "10                                                 ll                ca   \n",
      "11                                                  u                fr   \n",
      "12  the invention discloses a hydrogen energy auto...                en   \n",
      "13  the invention discloses a solar energy storage...                en   \n",
      "14                                                                error   \n",
      "15                                                                error   \n",
      "16                                fsrulngfsrufsrufsru                de   \n",
      "17  the invention discloses a wind power generatio...                en   \n",
      "18  the application discloses a solar energy absor...                en   \n",
      "19                                                                error   \n",
      "\n",
      "                                           title_text title_language  \n",
      "0   adaptable dc ac inverter drive system and oper...             en  \n",
      "1   system for providing the energy from a single ...             en  \n",
      "2       verfahren zum steuern einer windenergieanlage             de  \n",
      "3       verfahren zum steuern einer windenergieanlage             de  \n",
      "4   control method for optimizing solar to power e...             en  \n",
      "5   low carbon running saline wastewater treatment...             en  \n",
      "6   water ecological remediation device convenient...             en  \n",
      "7   cold and hot medium energy storage hot water a...             en  \n",
      "8   solar energy respiratory wall based on princip...             en  \n",
      "9                                                              error  \n",
      "10                                                             error  \n",
      "11  solar photovoltaic aluminum frame protection s...             ro  \n",
      "12                                                             error  \n",
      "13                                                             error  \n",
      "14                umbrella with illumination function             en  \n",
      "15  water conservancy water and electricity detect...             en  \n",
      "16  shipborne cold energy and wind energy hybrid p...             en  \n",
      "17               wind power generation driving device             en  \n",
      "18        solar energy absorption coating steel plate             en  \n",
      "19  water and electricity control method device eq...             en  \n"
     ]
    }
   ],
   "source": [
    "print(results_json[['abstract_text', 'abstract_language', 'title_text', 'title_language']].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9764316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b81fd4f6",
   "metadata": {},
   "source": [
    "#### Handle duplicates - don't run yet \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f7f0e3",
   "metadata": {},
   "source": [
    "We decided to handle duplicates after convertion of columns (for easier process and to avoid overwriting the code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d281366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows to ensure duplicates have been removed\n",
    "print(results_json.head())\n",
    "\n",
    "# Check for any remaining duplicates\n",
    "print(f\"Remaining duplicates: {results_json.duplicated().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6817dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop duplicates JSON\n",
    "# Convert list columns to strings\n",
    "for col in results_json.columns:\n",
    "    if isinstance(results_json[col].iloc[0], list):  # Check if the first cell contains a list\n",
    "        results_json[col] = results_json[col].apply(lambda x: json.dumps(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000b44ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all entries in 'inventor' are stringified JSON\n",
    "results_json['inventor'] = results_json['inventor'].apply(\n",
    "    lambda x: json.dumps(x) if isinstance(x, list) else '[]' if x is None else x\n",
    ")\n",
    "\n",
    "# Verify the conversion once more\n",
    "print(\"After conversion:\")\n",
    "for col in results_json.columns:\n",
    "    print(f\"{col} type:\", type(results_json[col].iloc[0]))\n",
    "\n",
    "# Now try to find duplicates again\n",
    "duplicates = results_json.duplicated()\n",
    "print(f\"There are {duplicates.sum()} duplicate rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5ed8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now you can drop duplicates\n",
    "#results_json.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8c2ab5",
   "metadata": {},
   "source": [
    "## CSV PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c30933",
   "metadata": {},
   "source": [
    "#### CT_Evaluation cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4a5ec2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows:\n",
      "   example_id  question_id                                           question  \\\n",
      "0           1            1  What is the innovation behind Leclanché's new ...   \n",
      "1           2            2       What is the EU’s Green Deal Industrial Plan?   \n",
      "2           3            2       What is the EU’s Green Deal Industrial Plan?   \n",
      "3           4            3  What are the four focus areas of the EU's Gree...   \n",
      "4           5            4  When did the cooperation between GM and Honda ...   \n",
      "\n",
      "                                      relevant_chunk  \\\n",
      "0  Leclanché said it has developed an environment...   \n",
      "1  The Green Deal Industrial Plan is a bid by the...   \n",
      "2  The European counterpart to the US Inflation R...   \n",
      "3  The new plan is fundamentally focused on four ...   \n",
      "4  What caught our eye was a new hookup between G...   \n",
      "\n",
      "                                         article_url  \n",
      "0  https://www.sgvoice.net/strategy/technology/23...  \n",
      "1  https://www.sgvoice.net/policy/25396/eu-seeks-...  \n",
      "2  https://www.pv-magazine.com/2023/02/02/europea...  \n",
      "3  https://www.sgvoice.net/policy/25396/eu-seeks-...  \n",
      "4  https://cleantechnica.com/2023/05/08/general-m...  \n"
     ]
    }
   ],
   "source": [
    "#Look into data frame already uploaded at the beginning of the notebook\n",
    "\n",
    "print(\"First few rows:\")\n",
    "print(ct_evaluation.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "23541891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23 entries, 0 to 22\n",
      "Data columns (total 11 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   example_id             23 non-null     int64 \n",
      " 1   question_id            23 non-null     int64 \n",
      " 2   question               23 non-null     object\n",
      " 3   relevant_chunk         23 non-null     object\n",
      " 4   article_url            23 non-null     object\n",
      " 5   question_tokens        23 non-null     object\n",
      " 6   relevant_chunk_tokens  23 non-null     object\n",
      " 7   question_length        23 non-null     int64 \n",
      " 8   chunk_length           23 non-null     int64 \n",
      " 9   cleaned_article_url    23 non-null     object\n",
      " 10  domain                 23 non-null     object\n",
      "dtypes: int64(4), object(7)\n",
      "memory usage: 2.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nData information:\")\n",
    "print(ct_evaluation.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4185e306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "example_id        0\n",
      "question_id       0\n",
      "question          0\n",
      "relevant_chunk    0\n",
      "article_url       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each column\n",
    "missing_data = ct_evaluation.isnull().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_data)\n",
    "# No missing data, which simplyify our cleaning steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d85423a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for ct_evaluation:\n",
      "                         type  unique_values  missing_values   0.0  0.25  \\\n",
      "article_url            object           21.0               0   NaN   NaN   \n",
      "chunk_length            int64           22.0               0  17.0  28.5   \n",
      "example_id              int64           23.0               0   1.0   6.5   \n",
      "question               object           21.0               0   NaN   NaN   \n",
      "question_id             int64           21.0               0   1.0   5.5   \n",
      "question_length         int64           12.0               0   4.0   9.0   \n",
      "question_tokens        object            NaN               0   NaN   NaN   \n",
      "relevant_chunk         object           23.0               0   NaN   NaN   \n",
      "relevant_chunk_tokens  object            NaN               0   NaN   NaN   \n",
      "\n",
      "                        0.5  0.75    1.0  range   iqr  \n",
      "article_url             NaN   NaN    NaN    NaN   NaN  \n",
      "chunk_length           40.0  61.5  109.0   92.0  33.0  \n",
      "example_id             12.0  17.5   23.0   22.0  11.0  \n",
      "question                NaN   NaN    NaN    NaN   NaN  \n",
      "question_id            11.0  16.5   21.0   20.0  11.0  \n",
      "question_length        10.0  13.5   21.0   17.0   4.5  \n",
      "question_tokens         NaN   NaN    NaN    NaN   NaN  \n",
      "relevant_chunk          NaN   NaN    NaN    NaN   NaN  \n",
      "relevant_chunk_tokens   NaN   NaN    NaN    NaN   NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_summary(df):\n",
    "    # Identify non-hashable columns (e.g., columns with lists)\n",
    "    non_hashable_columns = [col for col in df.columns if isinstance(df[col].dropna().iloc[0], list)]\n",
    "    \n",
    "    # Exclude non-hashable columns from the nunique calculation\n",
    "    hashable_columns = df.drop(columns=non_hashable_columns)\n",
    "    \n",
    "    # Essentials: type, unique values, missing values\n",
    "    summary = pd.DataFrame({\n",
    "        'type': df.dtypes,\n",
    "        'unique_values': hashable_columns.nunique(),\n",
    "        'missing_values': df.isnull().sum()\n",
    "    })\n",
    "    \n",
    "    # Quantile statistics for numeric columns only\n",
    "    numeric_cols = df.select_dtypes(include='number')\n",
    "    quantiles = numeric_cols.quantile([0, 0.25, 0.5, 0.75, 1]).transpose()\n",
    "    \n",
    "    # Add quantile stats to the summary\n",
    "    summary_stats = pd.concat([summary, quantiles], axis=1, sort=False)\n",
    "    \n",
    "    # Compute range and interquartile range (IQR)\n",
    "    if not numeric_cols.empty:  # Only calculate if there are numeric columns\n",
    "        summary_stats['range'] = summary_stats[1.0] - summary_stats[0.0]\n",
    "        summary_stats['iqr'] = summary_stats[0.75] - summary_stats[0.25]\n",
    "    \n",
    "    return summary_stats\n",
    "\n",
    "# Apply the summary function to your datasets\n",
    "ct_evaluation_summary = generate_summary(ct_evaluation)\n",
    "# ct_media_summary = generate_summary(ct_media) # Uncomment and replace with your actual DataFrame name\n",
    "\n",
    "# Display the summaries\n",
    "print(\"Summary for ct_evaluation:\")\n",
    "print(ct_evaluation_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "0975bc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique characters in 'question' column:\n",
      "[' ', '\"', \"'\", ',', '-', '0', '1', '2', '3', '5', '?', 'A', 'C', 'D', 'E', 'G', 'H', 'I', 'L', 'M', 'P', 'S', 'U', 'W', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'y', 'é', '’']\n",
      "\n",
      "Unique characters in 'relevant_chunk' column:\n",
      "[' ', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '8', '9', ':', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Z', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'é', '–', '’', '“', '”']\n"
     ]
    }
   ],
   "source": [
    "# Look into unique characters to indentify which ones to remove\n",
    "# Create sets to hold unique characters\n",
    "unique_chars_question = set()\n",
    "unique_chars_chunk = set()\n",
    "\n",
    "# Update sets with characters from each row\n",
    "for question, chunk in zip(ct_evaluation['question'], ct_evaluation['relevant_chunk']):\n",
    "    unique_chars_question.update(question)\n",
    "    unique_chars_chunk.update(chunk)\n",
    "\n",
    "# Print the unique characters\n",
    "print(\"Unique characters in 'question' column:\")\n",
    "print(sorted(unique_chars_question))\n",
    "print(\"\\nUnique characters in 'relevant_chunk' column:\")\n",
    "print(sorted(unique_chars_chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f48f4d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized 'question' column:\n",
      "0    what is the innovation behind leclanche's new ...\n",
      "1          what is the eus green deal industrial plan?\n",
      "2          what is the eus green deal industrial plan?\n",
      "3    what are the four focus areas of the eu's gree...\n",
      "4    when did the cooperation between gm and honda ...\n",
      "Name: question, dtype: object\n",
      "\n",
      "Standardized 'relevant_chunk' column:\n",
      "0    leclanche said it has developed an environment...\n",
      "1    the green deal industrial plan is a bid by the...\n",
      "2    the european counterpart to the us inflation r...\n",
      "3    the new plan is fundamentally focused on four ...\n",
      "4    what caught our eye was a new hookup between g...\n",
      "Name: relevant_chunk, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def standardize_text(text):\n",
    "    # Normalize and convert to lowercase\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8').lower()\n",
    "    \n",
    "    # Replace special apostrophes and quotation marks\n",
    "    text = text.replace('’', \"'\").replace('“', '\"').replace('”', '\"')\n",
    "    \n",
    "    # Standardize dashes\n",
    "    text = text.replace('–', '-')  # Replace en-dash with hyphen\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to both 'question' and 'relevant_chunk' columns\n",
    "ct_evaluation['question'] = ct_evaluation['question'].apply(standardize_text)\n",
    "ct_evaluation['relevant_chunk'] = ct_evaluation['relevant_chunk'].apply(standardize_text)\n",
    "\n",
    "# Display the cleaned text to confirm changes\n",
    "print(\"Standardized 'question' column:\")\n",
    "print(ct_evaluation['question'].head())\n",
    "print(\"\\nStandardized 'relevant_chunk' column:\")\n",
    "print(ct_evaluation['relevant_chunk'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "83282da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized 'question' column with lengths:\n",
      "14 tokens: ['what', 'is', 'the', 'innovation', 'behind', 'leclanche', \"'s\", 'new', 'method', 'to', 'produce', 'lithium-ion', 'batteries', '?']\n",
      "9 tokens: ['what', 'is', 'the', 'eus', 'green', 'deal', 'industrial', 'plan', '?']\n",
      "9 tokens: ['what', 'is', 'the', 'eus', 'green', 'deal', 'industrial', 'plan', '?']\n",
      "15 tokens: ['what', 'are', 'the', 'four', 'focus', 'areas', 'of', 'the', 'eu', \"'s\", 'green', 'deal', 'industrial', 'plan', '?']\n",
      "14 tokens: ['when', 'did', 'the', 'cooperation', 'between', 'gm', 'and', 'honda', 'on', 'fuel', 'cell', 'vehicles', 'start', '?']\n",
      "\n",
      "Tokenized 'relevant_chunk' column with lengths:\n",
      "44 tokens: ['leclanche', 'said', 'it', 'has', 'developed', 'an', 'environmentally', 'friendly', 'way', 'to', 'produce', 'lithium-ion', '(', 'li-ion', ')', 'batteries', '.', 'it', 'has', 'replaced', 'highly', 'toxic', 'organic', 'solvents', ',', 'commonly', 'used', 'in', 'the', 'production', 'process', ',', 'with', 'a', 'water-based', 'process', 'to', 'make', 'nickel-manganese-cobalt-aluminium', 'cathodes', '(', 'nmca', ')', '.']\n",
      "50 tokens: ['the', 'green', 'deal', 'industrial', 'plan', 'is', 'a', 'bid', 'by', 'the', 'eu', 'to', 'make', 'its', 'net', 'zero', 'industry', 'more', 'competitive', 'and', 'to', 'accelerate', 'its', 'transition', 'to', 'net', 'zero', '.', 'it', 'intends', 'to', 'support', 'the', 'expansion', 'of', 'european', 'manufacturing', 'of', 'technologies', ',', 'goods', 'and', 'services', 'needed', 'to', 'achieve', 'its', 'climate', 'targets', '.']\n",
      "40 tokens: ['the', 'european', 'counterpart', 'to', 'the', 'us', 'inflation', 'reduction', 'act', '(', 'ira', ')', 'aims', 'to', 'create', 'an', 'environment', 'that', 'is', 'conducive', 'to', 'increasing', 'the', 'european', 'union', \"'s\", 'manufacturing', 'capacity', 'of', 'net-zero', 'technologies', ',', 'to', 'improve', 'the', 'competitiveness', 'of', 'european', 'industry', '.']\n",
      "51 tokens: ['the', 'new', 'plan', 'is', 'fundamentally', 'focused', 'on', 'four', 'areas', ',', 'or', 'pillars', ':', 'the', 'regulatory', 'environment', ',', 'access', 'to', 'finance', ',', 'enhancing', 'skills', ',', 'and', 'improving', 'supply', 'chain', 'resilience', '.', 'it', 'also', 'builds', 'on', 'other', 'initiatives', ',', 'such', 'as', 'repowereu', ',', 'as', 'well', 'as', 'the', 'strength', 'of', 'the', 'single', 'market', '.']\n",
      "64 tokens: ['what', 'caught', 'our', 'eye', 'was', 'a', 'new', 'hookup', 'between', 'gm', 'and', 'honda', '.', 'honda', 'was', 'also', 'hammering', 'away', 'at', 'the', 'challenge', 'of', 'introducing', 'fuel', 'cell', 'vehicles', 'to', 'the', 'us', 'market', '.', 'the', 'collaboration', 'launched', 'in', 'july', 'of', '2013', ',', 'providing', 'for', 'the', 'two', 'companies', 'to', 'share', 'the', 'combined', 'total', 'of', '1,200', 'fuel', 'cell', 'patents', 'they', 'compiled', 'in', 'the', 'years', 'leading', 'up', 'to', '2012', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\maaru\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Ensure you've downloaded the necessary NLTK resource\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define the tokenization function using NLTK\n",
    "def tokenize_text_nltk(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens, len(tokens)\n",
    "\n",
    "# Apply the tokenization function to the 'question' and 'relevant_chunk' columns\n",
    "ct_evaluation['question_tokens'], ct_evaluation['question_length'] = zip(*ct_evaluation['question'].apply(tokenize_text_nltk))\n",
    "ct_evaluation['relevant_chunk_tokens'], ct_evaluation['chunk_length'] = zip(*ct_evaluation['relevant_chunk'].apply(tokenize_text_nltk))\n",
    "\n",
    "# Display the first few tokenized entries and their lengths to confirm\n",
    "print(\"Tokenized 'question' column with lengths:\")\n",
    "for tokens, length in zip(ct_evaluation['question_tokens'].head(), ct_evaluation['question_length'].head()):\n",
    "    print(f\"{length} tokens: {tokens}\")\n",
    "\n",
    "print(\"\\nTokenized 'relevant_chunk' column with lengths:\")\n",
    "for tokens, length in zip(ct_evaluation['relevant_chunk_tokens'].head(), ct_evaluation['chunk_length'].head()):\n",
    "    print(f\"{length} tokens: {tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8c42edd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype                                                        object\n",
      "nunique                                                          21\n",
      "count                                                            23\n",
      "nunique                                                          21\n",
      "unique            [https://www.sgvoice.net/strategy/technology/2...\n",
      "missing_values                                                    0\n",
      "Name: article_url, dtype: object\n"
     ]
    }
   ],
   "source": [
    "### URL cleaning\n",
    "\n",
    "# Summary of the article_url column\n",
    "url_summary = ct_evaluation['article_url'].agg(['dtype', 'nunique', 'count', pd.Series.nunique, pd.Series.unique])\n",
    "\n",
    "# Check for missing values\n",
    "url_summary['missing_values'] = ct_evaluation['article_url'].isnull().sum()\n",
    "\n",
    "# Display the summary\n",
    "print(url_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "a9c87cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          article_url  \\\n",
      "0   https://www.sgvoice.net/strategy/technology/23...   \n",
      "1   https://www.sgvoice.net/policy/25396/eu-seeks-...   \n",
      "2   https://www.pv-magazine.com/2023/02/02/europea...   \n",
      "3   https://www.sgvoice.net/policy/25396/eu-seeks-...   \n",
      "4   https://cleantechnica.com/2023/05/08/general-m...   \n",
      "5   https://solarindustrymag.com/scout-and-colgate...   \n",
      "6   https://cleantechnica.com/2023/01/02/the-wait-...   \n",
      "7   https://cleantechnica.com/2023/05/15/what-does...   \n",
      "8   https://cleantechnica.com/2023/05/15/mississip...   \n",
      "9   https://cleantechnica.com/2023/05/18/solar-pan...   \n",
      "10  https://www.azocleantech.com/news.aspx?newsID=...   \n",
      "11  https://www.azocleantech.com/news.aspx?newsID=...   \n",
      "12  https://www.azocleantech.com/news.aspx?newsID=...   \n",
      "13  https://www.azocleantech.com/news.aspx?newsID=...   \n",
      "14  https://www.azocleantech.com/news.aspx?newsID=...   \n",
      "15  https://www.thinkgeoenergy.com/japan-and-icela...   \n",
      "16  https://www.thinkgeoenergy.com/seequent-expand...   \n",
      "17  https://www.pv-magazine.com/2023/03/31/new-sof...   \n",
      "18  https://cleantechnica.com/2022/12/18/agrivolta...   \n",
      "19  https://www.pv-magazine.com/2023/04/08/high-ti...   \n",
      "20  https://www.pv-magazine.com/2023/04/08/high-ti...   \n",
      "21  https://cleantechnica.com/2023/04/10/solar-pow...   \n",
      "22  https://www.pv-magazine.com/2021/01/15/germani...   \n",
      "\n",
      "                                  cleaned_article_url                  domain  \n",
      "0   https://www.sgvoice.net/strategy/technology/23...         www.sgvoice.net  \n",
      "1   https://www.sgvoice.net/policy/25396/eu-seeks-...         www.sgvoice.net  \n",
      "2   https://www.pv-magazine.com/2023/02/02/europea...     www.pv-magazine.com  \n",
      "3   https://www.sgvoice.net/policy/25396/eu-seeks-...         www.sgvoice.net  \n",
      "4   https://cleantechnica.com/2023/05/08/general-m...       cleantechnica.com  \n",
      "5   https://solarindustrymag.com/scout-and-colgate...    solarindustrymag.com  \n",
      "6   https://cleantechnica.com/2023/01/02/the-wait-...       cleantechnica.com  \n",
      "7   https://cleantechnica.com/2023/05/15/what-does...       cleantechnica.com  \n",
      "8   https://cleantechnica.com/2023/05/15/mississip...       cleantechnica.com  \n",
      "9   https://cleantechnica.com/2023/05/18/solar-pan...       cleantechnica.com  \n",
      "10             https://www.azocleantech.com/news.aspx    www.azocleantech.com  \n",
      "11             https://www.azocleantech.com/news.aspx    www.azocleantech.com  \n",
      "12             https://www.azocleantech.com/news.aspx    www.azocleantech.com  \n",
      "13             https://www.azocleantech.com/news.aspx    www.azocleantech.com  \n",
      "14             https://www.azocleantech.com/news.aspx    www.azocleantech.com  \n",
      "15  https://www.thinkgeoenergy.com/japan-and-icela...  www.thinkgeoenergy.com  \n",
      "16  https://www.thinkgeoenergy.com/seequent-expand...  www.thinkgeoenergy.com  \n",
      "17  https://www.pv-magazine.com/2023/03/31/new-sof...     www.pv-magazine.com  \n",
      "18  https://cleantechnica.com/2022/12/18/agrivolta...       cleantechnica.com  \n",
      "19  https://www.pv-magazine.com/2023/04/08/high-ti...     www.pv-magazine.com  \n",
      "20  https://www.pv-magazine.com/2023/04/08/high-ti...     www.pv-magazine.com  \n",
      "21  https://cleantechnica.com/2023/04/10/solar-pow...       cleantechnica.com  \n",
      "22  https://www.pv-magazine.com/2021/01/15/germani...     www.pv-magazine.com  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from urllib.parse import urlparse, urlunparse\n",
    "\n",
    "def clean_url(url):\n",
    "    # Parse the URL\n",
    "    parsed_url = urlparse(url.lower())\n",
    "    # Reconstruct without query and fragment\n",
    "    cleaned_url = urlunparse((parsed_url.scheme, parsed_url.netloc, parsed_url.path, '', '', ''))\n",
    "    return cleaned_url\n",
    "\n",
    "def extract_domain(url):\n",
    "    # Parse the URL and extract the domain\n",
    "    domain = urlparse(url.lower()).netloc\n",
    "    return domain\n",
    "\n",
    "# Apply cleaning to the article_url column\n",
    "ct_evaluation['cleaned_article_url'] = ct_evaluation['article_url'].apply(clean_url)\n",
    "ct_evaluation['domain'] = ct_evaluation['article_url'].apply(extract_domain)\n",
    "\n",
    "# Display the cleaned URLs and domains\n",
    "print(ct_evaluation[['article_url', 'cleaned_article_url', 'domain']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a0885e",
   "metadata": {},
   "source": [
    "#### CT_Media Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "da34cbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows:\n",
      "   Unnamed: 0                                              title        date  \\\n",
      "0        1280  Qatar to Slash Emissions as LNG Expansion Adva...  2021-01-13   \n",
      "1        1281               India Launches Its First 700 MW PHWR  2021-01-15   \n",
      "2        1283              New Chapter for US-China Energy Trade  2021-01-20   \n",
      "3        1284  Japan: Slow Restarts Cast Doubt on 2030 Energy...  2021-01-22   \n",
      "4        1285     NYC Pension Funds to Divest Fossil Fuel Shares  2021-01-25   \n",
      "\n",
      "  author                                            content       domain  \\\n",
      "0    NaN  [\"Qatar Petroleum ( QP) is targeting aggressiv...  energyintel   \n",
      "1    NaN  [\"• Nuclear Power Corp. of India Ltd. ( NPCIL)...  energyintel   \n",
      "2    NaN  [\"New US President Joe Biden took office this ...  energyintel   \n",
      "3    NaN  [\"The slow pace of Japanese reactor restarts c...  energyintel   \n",
      "4    NaN  [\"Two of New York City's largest pension funds...  energyintel   \n",
      "\n",
      "                                                 url  \n",
      "0  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
      "1  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
      "2  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
      "3  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
      "4  https://www.energyintel.com/0000017b-a7dc-de4c...  \n"
     ]
    }
   ],
   "source": [
    "print(\"First few rows:\")\n",
    "print(ct_media.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1ca6e29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary for ct_media:\n",
      "              type  unique_values  missing_values     0.0     0.25      0.5  \\\n",
      "Unnamed: 0   int64           9593               0  1280.0  17156.0  45991.0   \n",
      "title       object           9569               0     NaN      NaN      NaN   \n",
      "date        object            967               0     NaN      NaN      NaN   \n",
      "author      object              7            9562     NaN      NaN      NaN   \n",
      "content     object           9588               0     NaN      NaN      NaN   \n",
      "domain      object             19               0     NaN      NaN      NaN   \n",
      "url         object           9593               0     NaN      NaN      NaN   \n",
      "\n",
      "               0.75      1.0    range      iqr  \n",
      "Unnamed: 0  79250.0  81816.0  80536.0  62094.0  \n",
      "title           NaN      NaN      NaN      NaN  \n",
      "date            NaN      NaN      NaN      NaN  \n",
      "author          NaN      NaN      NaN      NaN  \n",
      "content         NaN      NaN      NaN      NaN  \n",
      "domain          NaN      NaN      NaN      NaN  \n",
      "url             NaN      NaN      NaN      NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def generate_summary(df):\n",
    "    # Essentials: type, unique values, missing values\n",
    "    summary = pd.DataFrame({\n",
    "        'type': df.dtypes,\n",
    "        'unique_values': df.nunique(),\n",
    "        'missing_values': df.isnull().sum()\n",
    "    })\n",
    "    \n",
    "    # Quantile statistics for numeric columns only\n",
    "    numeric_cols = df.select_dtypes(include='number')\n",
    "    quantiles = numeric_cols.quantile([0, 0.25, 0.5, 0.75, 1]).transpose()\n",
    "    \n",
    "    # Add quantile stats to the summary\n",
    "    summary_stats = pd.concat([summary, quantiles], axis=1)\n",
    "    \n",
    "    # Compute range and interquartile range (IQR)\n",
    "    summary_stats['range'] = summary_stats[1.0] - summary_stats[0.0]\n",
    "    summary_stats['iqr'] = summary_stats[0.75] - summary_stats[0.25]\n",
    "    \n",
    "    return summary_stats\n",
    "\n",
    "# Apply the summary function to both datasets\n",
    "ct_media_summary = generate_summary(ct_media)\n",
    "\n",
    "# Display the summaries\n",
    "print(\"\\nSummary for ct_media:\")\n",
    "print(ct_media_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ce5ce0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest date: 2021-01-01 00:00:00\n",
      "Latest date: 2023-12-05 00:00:00\n",
      "Date frequencies:\n",
      " 2021-01-01    3\n",
      "2021-01-02    1\n",
      "2021-01-03    2\n",
      "2021-01-04    5\n",
      "2021-01-05    8\n",
      "Name: date, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Handle date, look into consistency and earlies and latest date\n",
    "# Check the earliest and latest dates\n",
    "print(\"Earliest date:\", ct_media['date'].min())\n",
    "print(\"Latest date:\", ct_media['date'].max())\n",
    "\n",
    "# Check the frequency of each date to identify any unusual patterns\n",
    "date_counts = ct_media['date'].value_counts().sort_index()\n",
    "print(\"Date frequencies:\\n\", date_counts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "62360b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique characters in 'title': {'ü', 'ç', 'L', ')', 'U', 'í', '9', 'ä', 'u', 'ú', 'C', 'a', 'N', '™', 'P', 'b', '₂', 's', 'l', '⅓', '@', 'y', '&', '%', 'R', '‘', 'Z', '5', '×', '!', '+', 'J', 'H', \"'\", 'á', 'W', 'q', '°', '1', 'o', 'x', '[', '?', '6', 'g', 'Ø', 'É', ';', 'ö', '=', 'D', '/', ']', 'f', ' ', 'B', 'p', 'm', 'M', 'ë', 'E', 'e', 'k', 'T', '½', '2', '€', '’', 'ø', 'Q', '“', '–', '>', 'I', 'F', 'â', '\\u200b', '0', '3', 'w', 'é', '4', 'j', '(', '£', 'i', '…', '-', '.', '®', 'à', '7', '”', '⅙', '#', '`', 'h', ':', 'Ö', 'X', 'v', 'A', 'V', ',', '*', 'n', 'c', 'å', 'K', 'ó', '—', 'O', 'd', 'ē', '$', '~', 'S', 'z', 'Y', 'r', 'G', '8', 't'}\n",
      "Unique characters in 'content': {'ç', 'ï', '开', '🎉', 'ż', '9', 'ª', 'C', 'வ', 'æ', 'a', 'Ü', 'l', '⋅', 'Ł', 'ū', 'Í', '😳', 'м', '‑', 'ு', 'Ç', '🛢', 'Z', '🎄', 'ê', '×', 'ɑ', 'ù', 'H', 'χ', '}', 'Т', '‰', 'W', 'q', 'О', '🚀', 'р', '👏', '😍', '©', '，', 'x', '[', '6', 'й', '😀', 'Ø', 'с', '·', ']', '회', 'Æ', 'д', '👇', 'M', '\"', '毛', 'ы', '℃', 'k', '🇸', 'Ć', '斯', 'ل', '“', 'த', '–', '―', 'I', 'â', 'є', 'Þ', '️', '´', '4', 'а', 'j', '🏛', '£', '»', 'i', 'ம', '☹', 'С', 'h', 'ч', 'Č', '^', '«', '😬', 'ł', 'γ', 'A', 'V', '🚨', '🏽', '🏴', 'å', '—', '≥', '🏭', 'd', 'к', 'ð', 'ب', '🇬', 'ü', '🇪', '¡', 'ź', 'п', 'ت', '～', 'Г', '🚗', 'ī', 'о', 'ã', '◦', 'P', 'b', '₂', 'ி', 'х', '●', '─', 'ř', '화', 'е', 'R', '\\\\', '‘', '😢', 'J', '💀', 'л', 'ை', \"'\", 'ă', 'ю', '🇧', 'ف', 'á', '‚', '{', '′', '⁰', '1', 'ā', 'ϕ', 'g', ';', '℉', '/', 'ô', '±', 'П', 'я', 'î', 'B', 'p', 'Є', 'د', 'δ', '🏠', 'e', 'у', 'Ó', '球', '🚆', 'β', '🇲', 'ல', 'Б', '🌏', 'é', 'ﬁ', 'ß', 'ь', '(', '⃣', '🤔', 'ي', 'č', 'М', '한', '7', '”', '•', '✖', '#', '`', ':', '🌬', 'X', '𓃵', 'ا', 'ள', 'ز', ',', '김', 'K', 'ó', 'O', 'ē', '$', 'Р', 'в', 'S', 'Y', 'ș', 'ோ', '학', 'L', 'Д', 'ä', '🌊', 'з', 'Е', '≤', '́', 'ழ', 's', 'Å', 'Л', '″', '⅓', '💵', '¼', '%', '📸', 'µ', '5', 'º', 'Î', 'η', '!', '+', 'Á', '¹', 'ӧ', 'س', '¥', 'н', '⚡', 'ட', 'o', 'і', '⬇', '=', '🇽', '环', '̶', '🔸', '→', 'f', ' ', '✔', 'அ', '¢', '₹', 'ج', 'ō', '🚐', 'い', 'ì', 'Н', '🇩', 'E', 'š', '🇻', 'ò', '2', '·', '€', '🙂', '’', 'щ', '‒', '迈', '<', '³', 'ñ', 'و', '…', '-', 'è', 'ė', 'Ö', 'μ', 'v', 'ę', '😎', '*', 'Ω', '⅔', 'ன', 'c', 'Ä', 'ண', '🔗', 'б', 'z', 'У', '்', 'G', '선', '☀', 'ح', '„', ')', 'ě', 'أ', 'U', 'ć', 'í', 'ú', 'э', 'u', 'ε', 'З', 'N', '™', '💙', '²', '@', 'y', '&', 'ா', '대', '👀', '👉', '💚', 'ك', '🇳', 'ũ', 'ı', 'и', '°', 'ễ', '雨', 'õ', '🤷', '时', 'Δ', '≈', 'ц', 'В', '?', 'ீ', 'ń', 'ق', 'Š', 'É', 'ö', '|', 'D', '➡', 'ه', '🍃', 'm', '¾', 'ن', 'ë', '🔋', 'T', '‐', 'Ц', '🇨', '½', '五', 'α', 'ص', 'т', 'ø', '🚛', 'Q', '✊', '>', 'F', 'ய', '0', 'Ô', '3', 'உ', 'w', '🙏', 'Ш', 'م', 'ж', '₃', 'ą', 'ப', 'ر', 'È', '−', '.', 'Ñ', 'ž', '˚', '®', 'à', '㎡', '报', '😉', 'ф', 'ொ', 'Э', 'ﬂ', 'г', '🇺', 'ț', 'n', '§', 'ý', '乞', '❌', '∼', '🍇', 'Ś', '~', '형', 'ш', 'ї', 'r', '8', '牛', 't'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def unique_characters(column):\n",
    "    return set(''.join(column))\n",
    "\n",
    "# Load your data (assuming DataFrame is named ct_media)\n",
    "# ct_media = pd.read_csv('path_to_your_file.csv')\n",
    "\n",
    "# Inspect unique characters in the title\n",
    "title_chars = unique_characters(ct_media['title'])\n",
    "print(\"Unique characters in 'title':\", title_chars)\n",
    "\n",
    "# Inspect unique characters in the content\n",
    "content_chars = unique_characters(ct_media['content'])\n",
    "print(\"Unique characters in 'content':\", content_chars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e151aa3",
   "metadata": {},
   "source": [
    "### Cleaning Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "609a9d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    qatar to slash emissions as lng expansion adva...\n",
      "1                 india launches its first 700 mw phwr\n",
      "2                new chapter for us-china energy trade\n",
      "3    japan slow restarts cast doubt on 2030 energy ...\n",
      "4       nyc pension funds to divest fossil fuel shares\n",
      "Name: title, dtype: object\n",
      "Unique characters in 'title': {'7', 'q', 'e', 'h', 'k', '9', 'u', '1', 'v', '2', 'o', 'a', 'x', '6', 'n', 'b', 'l', 's', 'g', 'c', 'y', '0', '3', 'd', 'w', '5', '4', 'f', ' ', 'j', 'z', 'r', 'i', 'p', '8', '-', 't', 'm'}\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def clean_title(text):\n",
    "    # Normalize unicode characters and convert to lower\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8').lower()\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^\\w\\s-]', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the title column\n",
    "ct_media['title'] = ct_media['title'].apply(clean_title)\n",
    "\n",
    "# Display the cleaned titles\n",
    "print(ct_media['title'].head())\n",
    "\n",
    "#examine unique characters again\n",
    "title_chars = unique_characters(ct_media['title'])\n",
    "print(\"Unique characters in 'title':\", title_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdc48a4",
   "metadata": {},
   "source": [
    "### Cleaning content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "2d291545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    qatar petroleum  qp is targeting aggressive cu...\n",
      "1     nuclear power corp. of india ltd.  npcil sync...\n",
      "2    new us president joe biden took office this we...\n",
      "3    the slow pace of japanese reactor restarts con...\n",
      "4    two of new york citys largest pension funds sa...\n",
      "Name: content, dtype: object\n",
      "Unique characters in 'content': {'7', 'q', 'e', 'h', 'k', '9', 'u', '1', 'v', '2', 'o', 'a', ',', 'x', '6', 'n', 'b', 's', 'l', 'g', 'c', 'y', '0', '3', 'd', 'w', '5', '4', 'f', ' ', 'j', 'z', 'r', 'i', 'p', '8', '-', 't', 'm', '.'}\n"
     ]
    }
   ],
   "source": [
    "def clean_content(text):\n",
    "    # Normalize unicode characters\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8').lower()\n",
    "    # Remove HTML tags (if any)\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    # Remove emojis\n",
    "    text = re.sub(r'[^\\w\\s.,-]', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the content column\n",
    "ct_media['content'] = ct_media['content'].apply(clean_content)\n",
    "\n",
    "# Display the cleaned content\n",
    "print(ct_media['content'].head())\n",
    "\n",
    "# Inspect unique characters in the content\n",
    "content_chars = unique_characters(ct_media['content'])\n",
    "print(\"Unique characters in 'content':\", content_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8269816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "469013d8",
   "metadata": {},
   "source": [
    "#### TOKANIZATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "8900aca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     tokenized_title  title_token_count  \\\n",
      "0  [qatar, to, slash, emissions, as, lng, expansi...                  8   \n",
      "1       [india, launches, its, first, 700, mw, phwr]                  7   \n",
      "2       [new, chapter, for, us-china, energy, trade]                  6   \n",
      "3  [japan, slow, restarts, cast, doubt, on, 2030,...                  9   \n",
      "4  [nyc, pension, funds, to, divest, fossil, fuel...                  8   \n",
      "\n",
      "                                   tokenized_content  content_token_count  \n",
      "0  [qatar, petroleum, qp, is, targeting, aggressi...                  472  \n",
      "1  [nuclear, power, corp., of, india, ltd., npcil...                  579  \n",
      "2  [new, us, president, joe, biden, took, office,...                  767  \n",
      "3  [the, slow, pace, of, japanese, reactor, resta...                  737  \n",
      "4  [two, of, new, york, citys, largest, pension, ...                  421  \n"
     ]
    }
   ],
   "source": [
    "# Example of tokenization using NLTK for whole dataset\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# You might need to download the NLTK tokenizer resources\n",
    "#nltk.download('punkt')\n",
    "\n",
    "# Applying tokenization\n",
    "ct_media['tokenized_content'] = ct_media['content'].apply(word_tokenize)\n",
    "ct_media['tokenized_title'] = ct_media['title'].apply(word_tokenize)\n",
    "\n",
    "# Count tokens in both content and title\n",
    "ct_media['content_token_count'] = ct_media['tokenized_content'].apply(len)\n",
    "ct_media['title_token_count'] = ct_media['tokenized_title'].apply(len)\n",
    "\n",
    "# Display the first few entries with token counts\n",
    "print(ct_media[['tokenized_title', 'title_token_count', 'tokenized_content', 'content_token_count']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09891bfb",
   "metadata": {},
   "source": [
    "#### CONTENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "f95b3cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maaru\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 545695), ('the', 411413), ('to', 221504), ('and', 216305), ('of', 203639), ('.', 186691), ('in', 149921), ('a', 132507), ('for', 92227), ('is', 86452)]\n"
     ]
    }
   ],
   "source": [
    "# Frequency distribution of words\n",
    "from nltk.probability import FreqDist\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Flatten the list of tokens and count the frequencies\n",
    "all_tokens = [token for sublist in ct_media['tokenized_content'] for token in sublist]\n",
    "freq_dist = FreqDist(all_tokens)\n",
    "\n",
    "# Print the 10 most common words\n",
    "print(freq_dist.most_common(10))\n",
    "\n",
    "# Stopword removal\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to remove stopwords\n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "# Apply stopword removal\n",
    "ct_media['filtered_content'] = ct_media['tokenized_content'].apply(remove_stopwords)\n",
    "\n",
    "# Example of TF-IDF Vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Join tokens back to strings\n",
    "ct_media['processed_content'] = ct_media['filtered_content'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Initialize a TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the processed content\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(ct_media['processed_content'])\n",
    "\n",
    "# You can explore tfidf_matrix here or proceed with machine learning modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d3111345",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TITLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5e269810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('to', 2447), ('in', 2062), ('for', 1904), ('energy', 1792), ('of', 1736), ('solar', 1694), ('the', 1619), ('pv', 1418), ('international', 1238), ('magazine', 1213)]\n"
     ]
    }
   ],
   "source": [
    "# Flatten the list of tokens from titles and count the frequencies\n",
    "all_title_tokens = [token for sublist in ct_media['tokenized_title'] for token in sublist]\n",
    "title_freq_dist = FreqDist(all_title_tokens)\n",
    "\n",
    "# Print the 10 most common words in titles\n",
    "print(title_freq_dist.most_common(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e3273329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [qatar, slash, emissions, lng, expansion, adva...\n",
      "1              [india, launches, first, 700, mw, phwr]\n",
      "2              [new, chapter, us-china, energy, trade]\n",
      "3    [japan, slow, restarts, cast, doubt, 2030, ene...\n",
      "4    [nyc, pension, funds, divest, fossil, fuel, sh...\n",
      "Name: filtered_title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Function to remove stopwords from titles\n",
    "ct_media['filtered_title'] = ct_media['tokenized_title'].apply(remove_stopwords)\n",
    "print(ct_media['filtered_title'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ac8b3ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join tokens back to strings for titles\n",
    "ct_media['processed_title'] = ct_media['filtered_title'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Initialize a TF-IDF Vectorizer for titles\n",
    "title_tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the processed titles\n",
    "title_tfidf_matrix = title_tfidf_vectorizer.fit_transform(ct_media['processed_title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ba97cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join tokens back to strings for titles\n",
    "ct_media['processed_title'] = ct_media['filtered_title'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Initialize a TF-IDF Vectorizer for titles\n",
    "title_tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the processed titles\n",
    "title_tfidf_matrix = title_tfidf_vectorizer.fit_transform(ct_media['processed_title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "fa736f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9593, 11886)\n"
     ]
    }
   ],
   "source": [
    "# If you need to explore the shape or type of the matrix\n",
    "print(title_tfidf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33ea988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a7fb6ab",
   "metadata": {},
   "source": [
    "#### Handle missing values in author - split at the end to create two separate dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ac476bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0                                              title  \\\n",
      "5564       76234  Ecotricity strikes landmark deal to secure geo...   \n",
      "5565       76235  'Getting to Zero ': New commission to explore ...   \n",
      "5566       76236  From floating turbines to carbon capture x-ray...   \n",
      "5567       76237  Electrification of harbour crane moves Port of...   \n",
      "5568       76238                            No hugging, no learning   \n",
      "\n",
      "           date               author  \\\n",
      "5564 2021-01-05      Cecilia Keating   \n",
      "5565 2021-01-05       James S Murray   \n",
      "5566 2021-01-06  BusinessGreen staff   \n",
      "5567 2021-01-06      Cecilia Keating   \n",
      "5568 2021-01-06       James S Murray   \n",
      "\n",
      "                                                content         domain  \\\n",
      "5564  [\"Geothermal energy in the UK took a major ste...  businessgreen   \n",
      "5565  ['Up to 10 million jobs across the UK are in c...  businessgreen   \n",
      "5566  ['UK science laboratories and testing faciliti...  businessgreen   \n",
      "5567  ['The Port of Tyne has made major strides towa...  businessgreen   \n",
      "5568  [\"It's no way to run a country. One of the man...  businessgreen   \n",
      "\n",
      "                                                    url  \n",
      "5564  https://www.businessgreen.com/news/4025357/eco...  \n",
      "5565  https://www.businessgreen.com/news/4025361/get...  \n",
      "5566  https://www.businessgreen.com/news/4025407/flo...  \n",
      "5567  https://www.businessgreen.com/news/4025401/ele...  \n",
      "5568  https://www.businessgreen.com/blog-post/402540...  \n",
      "   Unnamed: 0                                              title       date  \\\n",
      "0        1280  Qatar to Slash Emissions as LNG Expansion Adva... 2021-01-13   \n",
      "1        1281               India Launches Its First 700 MW PHWR 2021-01-15   \n",
      "2        1283              New Chapter for US-China Energy Trade 2021-01-20   \n",
      "3        1284  Japan: Slow Restarts Cast Doubt on 2030 Energy... 2021-01-22   \n",
      "4        1285     NYC Pension Funds to Divest Fossil Fuel Shares 2021-01-25   \n",
      "\n",
      "  author                                            content       domain  \\\n",
      "0    NaN  [\"Qatar Petroleum ( QP) is targeting aggressiv...  energyintel   \n",
      "1    NaN  [\"• Nuclear Power Corp. of India Ltd. ( NPCIL)...  energyintel   \n",
      "2    NaN  [\"New US President Joe Biden took office this ...  energyintel   \n",
      "3    NaN  [\"The slow pace of Japanese reactor restarts c...  energyintel   \n",
      "4    NaN  [\"Two of New York City's largest pension funds...  energyintel   \n",
      "\n",
      "                                                 url  \n",
      "0  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
      "1  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
      "2  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
      "3  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
      "4  https://www.energyintel.com/0000017b-a7dc-de4c...  \n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame only with entries that have an author\n",
    "ct_media_with_authors = ct_media.dropna(subset=['author'])\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(ct_media_with_authors.head())\n",
    "\n",
    "# Creating a DataFrame for entries without an author\n",
    "ct_media_without_authors = ct_media[ct_media['author'].isnull()]\n",
    "\n",
    "# Display the DataFrame without authors\n",
    "print(ct_media_without_authors.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "02cbb2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries with authors: 31\n",
      "Entries without authors: 9562\n",
      "\n",
      "First few entries with authors:\n",
      "      Unnamed: 0                                              title  \\\n",
      "5564       76234  Ecotricity strikes landmark deal to secure geo...   \n",
      "5565       76235  'Getting to Zero ': New commission to explore ...   \n",
      "5566       76236  From floating turbines to carbon capture x-ray...   \n",
      "5567       76237  Electrification of harbour crane moves Port of...   \n",
      "5568       76238                            No hugging, no learning   \n",
      "\n",
      "           date               author  \\\n",
      "5564 2021-01-05      Cecilia Keating   \n",
      "5565 2021-01-05       James S Murray   \n",
      "5566 2021-01-06  BusinessGreen staff   \n",
      "5567 2021-01-06      Cecilia Keating   \n",
      "5568 2021-01-06       James S Murray   \n",
      "\n",
      "                                                content         domain  \\\n",
      "5564  [\"Geothermal energy in the UK took a major ste...  businessgreen   \n",
      "5565  ['Up to 10 million jobs across the UK are in c...  businessgreen   \n",
      "5566  ['UK science laboratories and testing faciliti...  businessgreen   \n",
      "5567  ['The Port of Tyne has made major strides towa...  businessgreen   \n",
      "5568  [\"It's no way to run a country. One of the man...  businessgreen   \n",
      "\n",
      "                                                    url  \n",
      "5564  https://www.businessgreen.com/news/4025357/eco...  \n",
      "5565  https://www.businessgreen.com/news/4025361/get...  \n",
      "5566  https://www.businessgreen.com/news/4025407/flo...  \n",
      "5567  https://www.businessgreen.com/news/4025401/ele...  \n",
      "5568  https://www.businessgreen.com/blog-post/402540...  \n",
      "\n",
      "First few entries without authors:\n",
      "   Unnamed: 0                                              title       date  \\\n",
      "0        1280  Qatar to Slash Emissions as LNG Expansion Adva... 2021-01-13   \n",
      "1        1281               India Launches Its First 700 MW PHWR 2021-01-15   \n",
      "2        1283              New Chapter for US-China Energy Trade 2021-01-20   \n",
      "3        1284  Japan: Slow Restarts Cast Doubt on 2030 Energy... 2021-01-22   \n",
      "4        1285     NYC Pension Funds to Divest Fossil Fuel Shares 2021-01-25   \n",
      "\n",
      "  author                                            content       domain  \\\n",
      "0    NaN  [\"Qatar Petroleum ( QP) is targeting aggressiv...  energyintel   \n",
      "1    NaN  [\"• Nuclear Power Corp. of India Ltd. ( NPCIL)...  energyintel   \n",
      "2    NaN  [\"New US President Joe Biden took office this ...  energyintel   \n",
      "3    NaN  [\"The slow pace of Japanese reactor restarts c...  energyintel   \n",
      "4    NaN  [\"Two of New York City's largest pension funds...  energyintel   \n",
      "\n",
      "                                                 url  \n",
      "0  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
      "1  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
      "2  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
      "3  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
      "4  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
      "\n",
      "Domain counts for entries with authors:\n",
      "businessgreen    31\n",
      "Name: domain, dtype: int64\n",
      "\n",
      "Domain counts for entries without authors:\n",
      "cleantechnica            1861\n",
      "azocleantech             1627\n",
      "pv-magazine              1206\n",
      "energyvoice              1017\n",
      "solarindustrymag          673\n",
      "naturalgasintel           658\n",
      "thinkgeoenergy            645\n",
      "rechargenews              559\n",
      "solarpowerworldonline     505\n",
      "energyintel               234\n",
      "pv-tech                   232\n",
      "businessgreen             127\n",
      "greenprophet               80\n",
      "ecofriend                  38\n",
      "solarpowerportal.co        34\n",
      "eurosolar                  28\n",
      "decarbxpo                  19\n",
      "solarquarter               17\n",
      "indorenergy                 2\n",
      "Name: domain, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Inspect the separate dataset\n",
    "\n",
    "# Check the size of both datasets\n",
    "print(\"Entries with authors:\", ct_media_with_authors.shape[0])\n",
    "print(\"Entries without authors:\", ct_media_without_authors[ct_media_without_authors['author'].isnull()].shape[0])\n",
    "\n",
    "# Inspect the first few entries of the dataset with authors\n",
    "print(\"\\nFirst few entries with authors:\")\n",
    "print(ct_media_with_authors.head())\n",
    "\n",
    "# Inspect the first few entries of the dataset without authors\n",
    "print(\"\\nFirst few entries without authors:\")\n",
    "print(ct_media_without_authors[ct_media_without_authors['author'].isnull()].head())\n",
    "\n",
    "# Analyze domains to see if there are patterns related to missing authors\n",
    "print(\"\\nDomain counts for entries with authors:\")\n",
    "print(ct_media_with_authors['domain'].value_counts())\n",
    "\n",
    "print(\"\\nDomain counts for entries without authors:\")\n",
    "print(ct_media_without_authors[ct_media_without_authors['author'].isnull()]['domain'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc5d46c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
